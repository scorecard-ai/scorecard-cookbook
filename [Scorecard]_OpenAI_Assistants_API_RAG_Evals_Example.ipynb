{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scorecard-ai/scorecard-cookbook/blob/main/%5BScorecard%5D_OpenAI_Assistants_API_RAG_Evals_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo: OpenAI Assistants API RAG Evals Example\n",
        "\n",
        "## üßô‚Äç‚ôÇÔ∏è Instructions\n",
        "\n",
        "1. Create an account and [login to Scorecard](https://app.getscorecard.ai/). Copy your [API key](https://app.getscorecard.ai/settings).\n",
        "1. Add your Scorecard and OpenAI API Keys below.\n",
        "1. Go to `Runtime` -> `Run all`. Enjoy!"
      ],
      "metadata": {
        "id": "LjecdsSRPPai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üëâ API Keys\n",
        "\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = \"\" #@param { type: \"string\" }\n",
        "SCORECARD_API_KEY = \"\" #@param { type: \"string\" }\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"SCORECARD_API_KEY\"] = SCORECARD_API_KEY"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wAsJ8kJ6O1TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "xO5brg_tzz4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "#@markdown In order to keep the notebook working for all future users, we pin the dependency versions.\n",
        "\n",
        "!pip install scorecard-ai==0.1.12\n",
        "!pip install openai==1.14.3"
      ],
      "metadata": {
        "id": "B_wcdhcPzyQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5765ad-40dc-42ab-b07c-e1389976bde6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scorecard-ai==0.1.12\n",
            "  Downloading scorecard_ai-0.1.12-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from scorecard-ai==0.1.12) (0.27.0)\n",
            "Requirement already satisfied: pydantic<2.5.0,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from scorecard-ai==0.1.12) (2.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.12) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.12) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.12) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.12) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.12) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->scorecard-ai==0.1.12) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=1.9.2->scorecard-ai==0.1.12) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=1.9.2->scorecard-ai==0.1.12) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=1.9.2->scorecard-ai==0.1.12) (4.10.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->scorecard-ai==0.1.12) (1.2.0)\n",
            "Installing collected packages: scorecard-ai\n",
            "  Attempting uninstall: scorecard-ai\n",
            "    Found existing installation: scorecard-ai 0.1.10\n",
            "    Uninstalling scorecard-ai-0.1.10:\n",
            "      Successfully uninstalled scorecard-ai-0.1.10\n",
            "Successfully installed scorecard-ai-0.1.12\n",
            "Collecting openai==1.14.3\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.14.3) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (2.4.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.14.3) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.14.3) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.14.3) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.14.3) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.14.3) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.14.3) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.14.3) (2.10.1)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.11.1\n",
            "    Uninstalling openai-1.11.1:\n",
            "      Successfully uninstalled openai-1.11.1\n",
            "Successfully installed openai-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "from openai import OpenAI\n",
        "from scorecard.client import Scorecard\n",
        "from google.colab import files\n",
        "from typing import List, Tuple\n",
        "import asyncio\n",
        "import time"
      ],
      "metadata": {
        "id": "dod8Xp-5z5i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build your LLM system\n",
        "\n",
        "Now, let's define your system (aka system-under-test)! For this demo, we'll set up an OpenAI Assistants instance to perform RAG on the file provided."
      ],
      "metadata": {
        "id": "PQriXDnF0CVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload your document/data\n",
        "\n",
        "uploaded = files.upload()\n",
        "print(\"Upload done!\")\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "QLV9iBhxX5wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create an OpenAI Assistant\n",
        "\n",
        "client = OpenAI()\n",
        "file = client.files.create(\n",
        "  file=open(list(uploaded.keys())[0], \"rb\"),\n",
        "  purpose='assistants'\n",
        ")\n",
        "assistant = client.beta.assistants.create(\n",
        "    instructions=\"You have access to files containing my emails to answer questions.\",\n",
        "    name=\"RAG Assistant\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    file_ids=[file.id],\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")"
      ],
      "metadata": {
        "id": "CkBufgvqYgCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Call OpenAI to generate completion from the Assistant\n",
        "#@markdown Here we'll define an example of a multi-message prompt sent to OpenAI.\n",
        "\n",
        "def generate(query) -> Tuple[str, List[str]]:\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    run = client.beta.threads.create_and_run(\n",
        "        assistant_id=assistant.id,\n",
        "        thread={\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": query,\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "    )\n",
        "    run_id = run.id\n",
        "    thread_id = run.thread_id\n",
        "    print(f\"Run ID: {run_id}\")\n",
        "    print(f\"Thread ID: {thread_id}\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            run = client.beta.threads.runs.retrieve(\n",
        "                run_id=run_id, thread_id=thread_id\n",
        "            )\n",
        "            if run.completed_at:\n",
        "                elapsed_time = run.completed_at - run.created_at\n",
        "                formatted_elapsed_time = time.strftime(\n",
        "                    \"%H:%M:%S\", time.gmtime(elapsed_time)\n",
        "                )\n",
        "                print(f\"Run completed in {formatted_elapsed_time}\")\n",
        "                messages = client.beta.threads.messages.list(\n",
        "                    thread_id=thread_id\n",
        "                )\n",
        "                last_message = messages.data[0]\n",
        "\n",
        "                # Extract the message content\n",
        "                message_content = last_message.content[0].text\n",
        "                annotations = message_content.annotations\n",
        "                citations = []\n",
        "\n",
        "                # Iterate over the annotations and add footnotes\n",
        "                for index, annotation in enumerate(annotations):\n",
        "                    # Gather citations based on annotation attributes\n",
        "                    if (file_citation := getattr(annotation, 'file_citation', None)):\n",
        "                        citations.append(file_citation.quote)\n",
        "\n",
        "                response = message_content.value\n",
        "\n",
        "                return response, str(citations)\n",
        "            else:\n",
        "                time.sleep(0.2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while retrieving the run: {e}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "mxwAnPPackzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate your system\n",
        "\n",
        "### Pre-req: Create Metrics\n",
        "\n",
        "First, using the Scorecard application, create your metrics and scoring config. For this example,\n",
        "we can use something simple like a Helpfulness metric that determines whether\n",
        "the generation adheres to the user's request.\n",
        "\n",
        "Once you have created your scoring config, copy the ID and enter it below:"
      ],
      "metadata": {
        "id": "YCbMNYhl4IMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Metrics\n",
        "SCORING_CONFIG_ID = 1  #@param { type: \"number\" }"
      ],
      "metadata": {
        "id": "rWIaBWy_WvhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scorecard_client = Scorecard(\n",
        "    api_key=SCORECARD_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "RrENtkLPhINw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Create a basic Testset\n",
        "#@markdown Here we'll create a basic Testset that gets stored in Scorecard.\n",
        "\n",
        "client = Scorecard(\n",
        "    api_key=SCORECARD_API_KEY\n",
        ")\n",
        "\n",
        "# Create a Testset\n",
        "testset = client.testset.create(\n",
        "    name=\"RAG Email Demo\",\n",
        "    description=\"Demo of a testset created via Scorecard Python SDK\",\n",
        "    using_retrieval=True\n",
        ")\n",
        "\n",
        "# Add three testcases\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"What was said on January 2?\"\n",
        ")\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"How many times did I email Roland?\"\n",
        ")\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"What did I last say to Roland?\"\n",
        ")\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Testset:\")\n",
        "print(f\"https://app.getscorecard.ai/view-dataset/{testset.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqtQRU694Jft",
        "outputId": "2ed3b2e4-3256-4ac6-bd69-1c0d2774710f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Testset:\n",
            "https://app.getscorecard.ai/view-dataset/1597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Run Tests\n",
        "#@markdown Now we'll create a new Run to execute our LLM system above.\n",
        "\n",
        "from scorecard.types import RunStatus\n",
        "\n",
        "client = Scorecard(\n",
        "    api_key=SCORECARD_API_KEY\n",
        ")\n",
        "\n",
        "run = client.run.create(testset_id=testset.id)\n",
        "client.run.update_status(run_id=run.id, status=RunStatus.RUNNING_EXECUTION)\n",
        "\n",
        "for testcase in client.testset.get_testcases(testset_id=testset.id).results:\n",
        "  model_response = generate(query=testcase.user_query)\n",
        "  print(model_response)\n",
        "  client.testrecord.create(run_id=run.id,\n",
        "                           testset_id=testset.id,\n",
        "                           testcase_id=testcase.id,\n",
        "                           user_query=testcase.user_query,\n",
        "                           context=model_response[1],\n",
        "                           response=model_response[0])\n",
        "\n",
        "client.run.update_status(run_id=run.id, status=RunStatus.AWAITING_SCORING)\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Run:\")\n",
        "print(f\"https://app.getscorecard.ai/view-records/{run.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCc2EdyeRoIH",
        "outputId": "24eaa3cb-5998-42d1-857f-8ba3d4b8695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run ID: run_MN238gIBPWbIrqkvU41SCLCQ\n",
            "Thread ID: thread_LtxCRjTAsGQTGw3A2GeuQEj6\n",
            "Run completed in 00:00:33\n",
            "('I am unable to find the specific mention of January 2nd in the emails. It appears that scrolling through the document did not reveal any correspondence from that date. If you have any specific keywords or context about the content from January 2nd that you are looking for, it would help to narrow down the search. Otherwise, it might be that the emails from January 2nd are not included in the uploaded file. Can you please provide more information or guide me on how to proceed?', '[]')\n",
            "Run ID: run_lRUgq7cqkjPWydFEwikhq6IW\n",
            "Thread ID: thread_whGAvk6ffLqGCu9yNA6knu1x\n",
            "Run completed in 00:00:12\n",
            "('After scrolling through the document and seeing references to \"Roland,\" it appears that you have not directly emailed Roland. The instances of the name \"Roland\" found in the document are in the context of an email invitation list and RSVP for events where Roland is one of many recipients. If you are looking for direct email exchanges between you and Roland, they do not appear to be present in the portion of the document reviewed so far.\\n\\nWould you like me to continue searching through the rest of the document?', '[]')\n",
            "Run ID: run_nIuHG55vx7oh1YF89pJoClC8\n",
            "Thread ID: thread_NlvVa6Ef36mwi3nqa23XPgws\n",
            "Run completed in 00:00:12\n",
            "('The last thing you said to Roland, according to the available documents, was an invitation to an event titled \"RIP: Responding to Incidents Party\" that takes place annually from 4 pm to 5 pm on June 21 (Central Standard Time - Mexico City). The invitation included several details about joining the meeting and what would be discussed during the event„Äê9‚Ä†source„Äë.', \"['To:  Roland Gavrilescu; Mike Klaas; Patrick Bakke; Mike Kassoff; Aditya Kothari; Conrad\\\\nIrwin; Chuck Berlin; Desktop Team; nikhil@superhuman.com; Rachel Hyman; backend-team; Mobile Team; \\\\nBrian Zindler; Kevin Macek; Engineering team; Sachin Hegde; Cat Wilmers; Tim Boucher; \\\\nali@superhuman.com; Tim Sakhuja; Bruno Sylvain; Kenny Roethel; Erin Weisenfeld; Nico Berger; Ezra R√°ez; \\\\nAndrew Hershberger; Rafael Melo Cardoso; Meagan Pau; Nick Diaz; Grace Kim; Roberto Sonck; qa-\\\\nteam@superhuman.com; Will Chowattanakul; Peik Sia; Riley Ackerman; Kristine Adams; Pablo Gotuzzo; \\\\nMoez Bhatti; Laurel Johnescu; Sean Fitzgerald; Aidan Baack; Giulio Denardi; Gabe Shahbazian; Fabricio Jorge; \\\\nJonathan Moguilevsky; Matt Zaitley; Victor Barros; Emiliano Martinez Luque; Joanne Zhu; Barclay Walsh; \\\\nKyle Schumacher; Chris Bee; Katrina Festejo\\\\nSubject:  Invitation: RIP: Responding to Incidents Party @ Annually from 4pm to 5pm on June\\\\n21 (CDT) (Roland Gavrilescu)\\\\nAttachments: invite.ics\\\\n\\\\n\\\\nJoin with Google\\\\nMeet\\\\n\\\\n\\\\nMeeting link\\\\nmeet.google.com/rye-vwtc-cjr\\\\n\\\\n\\\\nJoin by phone\\\\n(US) +1 505-715-5327\\\\nPIN: 689336815\\\\n\\\\n\\\\nMore phone numbers\\\\n\\\\n\\\\nPeriodically we gather to review our incident handling procedures and test relevant tooling.\\\\n\\\\n\\\\nThis includes:\\\\n\\\\n\\\\n\\\\uffff Testing rollback/roll forward scripts on backend and desktop\\\\n\\\\uffff Testing restoring database restoring\\\\n\\\\uffff Testing redis outage handling\\\\n\\\\uffff Testing scripts that manipulate sends/reminders/relabels during incidents.\\\\n\\\\nPlease review the following Notion pages before this meeting:\\\\n* https://www.notion.so/superhuman/Handling-Product-Outages-Incident-Response-\\\\n640908e3cfd045f6af61eb23e4be52e1\\\\n* https://www.notion.so/superhuman/Pagerduty-Being-on-call-5f5e7f6236de4abbac32cd6e6c743a9a\\\\n\\\\n\\\\nWhe\\\\nn\\\\nAnnually from 4pm to 5pm on June 21 (Central Standard Time - Mexico City)\\\\n\\\\n\\\\nGuest\\\\ns\\\\nGaurav Karnik - organizer\\\\nMike Klaas - creator\\\\nPatrick Bakke\\\\nMike Kassoff\\\\nAditya Kothari\\\\nConrad Irwin\\\\nChuck Berlin\\\\nDesktop Team\\\\nnikhil@superhuman.com\\\\nRachel Hyman\\\\nbackend-team\\\\nMobile Team\\\\nBrian Zindler\\\\nKevin Macek\\\\nEngineering team\\\\nSachin Hegde\\\\nCat Wilmers\\\\nTim Boucher\\\\nKevin Belter\\\\nali@superhuman.com\\\\nTim Sakhuja\\\\nBruno Sylvain\\\\nKenny Roethel\\\\nErin Weisenfeld\\\\nNico Berger\\\\nEzra R√°ez\\\\nAndrew Hershberger\\\\n\\\\nRafael Melo Cardoso\\\\nMeagan Pau\\\\nNick Diaz\\\\nGrace Kim\\\\nRoberto Sonck\\\\nqa-team@superhuman.com\\\\nWill Chowattanakul\\\\nPeik Sia\\\\nRiley Ackerman\\\\nKristine Adams\\\\nPablo Gotuzzo\\\\nMoez Bhatti\\\\nLaurel Johnescu\\\\nSean Fitzgerald\\\\nAidan Baack\\\\nGiulio Denardi\\\\nGabe Shahbazian\\\\nFabricio Jorge\\\\nJonathan Moguilevsky\\\\nMatt Zaitley\\\\nVictor Barros\\\\nEmiliano Martinez Luque\\\\nJoanne Zhu\\\\nBarclay Walsh\\\\nKyle Schumacher\\\\nChris Bee\\\\nKatrina Festejo\\\\nRoland Gavrilescu\\\\nView all guest info\\\\n\\\\n\\\\nRSVP for roland@superhuman.com for all events in this series']\")\n",
            "Visit the Scorecard app to view your Run:\n",
            "https://app.getscorecard.ai/view-records/3111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Kick off Scoring\n",
        "#@markdown Once your run above is finished executing, hit the \"Run Scoring\" button to run scoring. Once that's done, visit the Results page:\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Results:\")\n",
        "print(f\"https://app.getscorecard.ai/view-grades/{run.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDVMDhAoWgL6",
        "outputId": "5d547bcd-e518-4e09-be79-49c42edd0f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Results:\n",
            "https://app.getscorecard.ai/view-grades/3109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "63ZKTkmjuyY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
