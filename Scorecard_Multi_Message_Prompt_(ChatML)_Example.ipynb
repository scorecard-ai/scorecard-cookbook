{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xO5brg_tzz4A"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scorecard-ai/scorecard-cookbook/blob/main/Scorecard_Multi_Message_Prompt_(ChatML)_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo: Scorecard Multi-Message Prompt (ChatML)\n",
        "## 🧙‍♂️ Instructions\n",
        "\n",
        "1. Create an account and [login to Scorecard](https://app.getscorecard.ai/). Copy your [API key](https://app.getscorecard.ai/settings).\n",
        "1. Add your Scorecard and OpenAI API Keys below.\n",
        "1. Go to `Runtime` -> `Run all`. Enjoy!"
      ],
      "metadata": {
        "id": "LjecdsSRPPai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 👉 API Keys\n",
        "\n",
        "OPENAI_API_KEY = \"\" #@param { type: \"string\" }\n",
        "SCORECARD_API_KEY = \"\" #@param { type: \"string\" }"
      ],
      "metadata": {
        "id": "wAsJ8kJ6O1TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "xO5brg_tzz4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "#@markdown In order to keep the notebook working for all future users, we pin the dependency versions.\n",
        "\n",
        "!pip install scorecard-ai==0.2.1\n",
        "!pip install openai==1.11.1"
      ],
      "metadata": {
        "id": "B_wcdhcPzyQ3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "from openai import OpenAI\n",
        "from scorecard.client import Scorecard"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dod8Xp-5z5i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build your LLM system\n",
        "\n",
        "Now, let's define your system (aka system-under-test)! For this demo, we'll set up an LLM call to generate the opening line of a story, where the user determines what the topic of the story will be."
      ],
      "metadata": {
        "id": "PQriXDnF0CVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define our multi-message prompt template\n",
        "\n",
        "PROMPT_TEMPLATE_1 = \"You are a helpful assistant.\" #@param { type:\"string\" }\n",
        "\n",
        "PROMPT_TEMPLATE_2 = \"Assist the user in crafting a story about {user_topic}.\" #@param { type:\"string\" }\n",
        "\n",
        "PROMPT_TEMPLATE_3 = \"I need a good opening line for my story. Please generate only the opening line.\" #@param { type:\"string\" }"
      ],
      "metadata": {
        "id": "-4PGlf0UQ2pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRiB7PWwzcu_"
      },
      "outputs": [],
      "source": [
        "#@title Call OpenAI to generate a story\n",
        "#@markdown Here we'll define an example of a multi-message prompt sent to OpenAI.\n",
        "\n",
        "def generate_story(user_topic: str) -> str:\n",
        "  client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",  # or \"gpt-4\" depending on your access and requirements\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": PROMPT_TEMPLATE_1},\n",
        "        {\"role\": \"system\", \"content\": PROMPT_TEMPLATE_2.format(user_topic=user_topic)},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_TEMPLATE_3}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate your system\n",
        "\n",
        "### Pre-req: Create Metrics\n",
        "\n",
        "First, using the Scorecard application, create your metrics and scoring config. For this example,\n",
        "we can use something simple like a Helpfulness metric that determines whether\n",
        "the generation adheres to the user's request.\n",
        "\n",
        "Once you have created your scoring config, copy the ID and enter it below:"
      ],
      "metadata": {
        "id": "YCbMNYhl4IMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Metrics\n",
        "SCORING_CONFIG_ID = 1  #@param { type: \"number\" }"
      ],
      "metadata": {
        "id": "rWIaBWy_WvhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Create a basic Testset\n",
        "#@markdown Here we'll create a basic Testset that gets stored in Scorecard.\n",
        "\n",
        "client = Scorecard(\n",
        "    api_key=SCORECARD_API_KEY\n",
        ")\n",
        "\n",
        "# Create a Testset\n",
        "testset = client.testset.create(\n",
        "    name=\"Story Opening Lines\",\n",
        "    description=\"Demo of a testset created via Scorecard Python SDK\",\n",
        "    using_retrieval=False\n",
        ")\n",
        "\n",
        "# Add three testcases\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"magical powers to control ice and snow\"\n",
        ")\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"a journey with a rugged iceman, his loyal reindeer, and a naive snowman\"\n",
        ")\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"the story of two royal sisters\"\n",
        ")\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Testset:\")\n",
        "print(f\"https://app.getscorecard.ai/view-dataset/{testset.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqtQRU694Jft",
        "outputId": "b6c54408-390a-408c-a31d-c06ce50798c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Testset:\n",
            "https://app.getscorecard.ai/view-dataset/786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Run Tests\n",
        "#@markdown Now we'll create a new Run to execute our LLM system above.\n",
        "\n",
        "from scorecard.types import RunStatus\n",
        "\n",
        "run = client.run.create(testset_id=testset.id)\n",
        "client.run.update_status(run_id=run.id, status=RunStatus.RUNNING_EXECUTION)\n",
        "\n",
        "for testcase in client.testset.get_testcases(testset_id=testset.id).results:\n",
        "  model_response = generate_story(user_topic=testcase.user_query)\n",
        "  client.testrecord.create(run_id=run.id,\n",
        "                           testset_id=testset.id,\n",
        "                           testcase_id=testcase.id,\n",
        "                           user_query=testcase.user_query,\n",
        "                           response=model_response)\n",
        "\n",
        "client.run.update_status(run_id=run.id, status=RunStatus.AWAITING_SCORING)\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Run:\")\n",
        "print(f\"https://app.getscorecard.ai/view-records/{run.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCc2EdyeRoIH",
        "outputId": "398b3377-bab7-4f78-cd56-80bbc7ffa690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Run:\n",
            "https://app.getscorecard.ai/view-records/2610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Kick off Scoring\n",
        "#@markdown Once your run above is finished executing, hit the \"Run Scoring\" button to run scoring. Once that's done, visit the Results page:\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Results:\")\n",
        "print(f\"https://app.getscorecard.ai/view-grades/{run.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "TDVMDhAoWgL6",
        "outputId": "d3e50122-3fc3-4d02-f8cf-60483e0c4d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Results:\n",
            "https://app.getscorecard.ai/view-grades/2610\n"
          ]
        }
      ]
    }
  ]
}
